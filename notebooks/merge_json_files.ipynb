{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# JSON File Merger\n",
        "\n",
        "This notebook merges two JSON files:\n",
        "1. A source file (like `uploaded_files-10.json`) containing file metadata\n",
        "2. A target file (like `uploaded_files-new.json`) containing updated IDs\n",
        "\n",
        "The output will be all entries from the source file but with IDs updated from the target file, matched by filename.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Required libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any\n",
        "import pandas as pd\n",
        "\n",
        "# Define file paths\n",
        "SOURCE_FILE = \"../example_upload_data/uploaded_files-100.json\"  # File with all metadata\n",
        "TARGET_FILE = \"../example_upload_data/uploaded_files-new.json\"  # File with new IDs\n",
        "OUTPUT_FILE = \"../example_upload_data/uploaded_files-merged-100.json\"  # Output file\n",
        "\n",
        "print(\"Required libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_json_file(file_path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load JSON file and return its contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        print(f\"✅ Successfully loaded {file_path}\")\n",
        "        print(f\"   Contains {len(data)} entries\")\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ File not found: {file_path}\")\n",
        "        return []\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"❌ JSON decode error in {file_path}: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "def create_filename_to_id_mapping(data: List[Dict[str, Any]]) -> Dict[str, int]:\n",
        "    \"\"\"Create a mapping from filename to ID.\"\"\"\n",
        "    mapping = {}\n",
        "    for entry in data:\n",
        "        if 'filename' in entry and 'id' in entry:\n",
        "            mapping[entry['filename']] = entry['id']\n",
        "    print(f\"Created mapping for {len(mapping)} filenames\")\n",
        "    return mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def merge_json_files(source_data: List[Dict[str, Any]], \n",
        "                    id_mapping: Dict[str, int]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Merge source data with new IDs from the mapping, removing duplicates.\n",
        "    \n",
        "    Args:\n",
        "        source_data: List of file entries from the source JSON\n",
        "        id_mapping: Dictionary mapping filename to new ID\n",
        "    \n",
        "    Returns:\n",
        "        List of merged entries with updated IDs (duplicates removed)\n",
        "    \"\"\"\n",
        "    merged_data = []\n",
        "    updated_count = 0\n",
        "    not_found_count = 0\n",
        "    duplicate_count = 0\n",
        "    seen_combinations = set()  # Track (filename, file_path) combinations\n",
        "    \n",
        "    for entry in source_data:\n",
        "        filename = entry.get('filename', '')\n",
        "        file_path = entry.get('file_path', '')\n",
        "        \n",
        "        # Create a unique key for this file\n",
        "        file_key = (filename, file_path)\n",
        "        \n",
        "        # Skip if we've already processed this exact file\n",
        "        if file_key in seen_combinations:\n",
        "            duplicate_count += 1\n",
        "            print(f\"🔄 Skipping duplicate: '{filename}' at '{file_path}'\")\n",
        "            continue\n",
        "            \n",
        "        seen_combinations.add(file_key)\n",
        "        \n",
        "        # Create a copy of the entry\n",
        "        merged_entry = entry.copy()\n",
        "        \n",
        "        if filename in id_mapping:\n",
        "            # Update the ID\n",
        "            old_id = merged_entry.get('id')\n",
        "            new_id = id_mapping[filename]\n",
        "            merged_entry['id'] = new_id\n",
        "            updated_count += 1\n",
        "            print(f\"Updated '{filename}': ID {old_id} → {new_id}\")\n",
        "        else:\n",
        "            not_found_count += 1\n",
        "            print(f\"⚠️  No new ID found for '{filename}' - keeping original ID {entry.get('id')}\")\n",
        "        \n",
        "        merged_data.append(merged_entry)\n",
        "    \n",
        "    print(f\"\\n📊 Merge Summary:\")\n",
        "    print(f\"   Total entries processed: {len(source_data)}\")\n",
        "    print(f\"   Duplicates removed: {duplicate_count}\")\n",
        "    print(f\"   Unique entries kept: {len(merged_data)}\")\n",
        "    print(f\"   IDs updated: {updated_count}\")\n",
        "    print(f\"   IDs unchanged: {not_found_count}\")\n",
        "    \n",
        "    return merged_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_json_file(data: List[Dict[str, Any]], file_path: str) -> bool:\n",
        "    \"\"\"Save data to JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"✅ Successfully saved {len(data)} entries to {file_path}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving to {file_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "def display_sample_data(data: List[Dict[str, Any]], title: str, max_items: int = 3):\n",
        "    \"\"\"Display sample data for verification.\"\"\"\n",
        "    print(f\"\\n{title}\")\n",
        "    print(\"=\" * len(title))\n",
        "    \n",
        "    if not data:\n",
        "        print(\"No data to display\")\n",
        "        return\n",
        "    \n",
        "    for i, entry in enumerate(data[:max_items]):\n",
        "        print(f\"\\nEntry {i+1}:\")\n",
        "        for key, value in entry.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "    \n",
        "    if len(data) > max_items:\n",
        "        print(f\"\\n... and {len(data) - max_items} more entries\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting JSON file merge process...\n",
            "\n",
            "Step 1: Loading source file...\n",
            "✅ Successfully loaded ../example_upload_data/uploaded_files-100.json\n",
            "   Contains 98 entries\n",
            "\n",
            "Sample from Source File\n",
            "=======================\n",
            "\n",
            "Entry 1:\n",
            "  id: 12\n",
            "  filename: Datenschutzerklärung Heier Grundschule.docx\n",
            "  file_path: app/data/uploads/Datenschutzerklärung Heier Grundschule.docx\n",
            "  created_at: 2025-05-15T11:12:25.702298\n",
            "  document_id: None\n",
            "  relative_path: Datenschutzerklärung Heier Grundschule.docx\n",
            "\n",
            "Entry 2:\n",
            "  id: 13\n",
            "  filename: Drop shipping.docx\n",
            "  file_path: app/data/uploads/Drop shipping.docx\n",
            "  created_at: 2025-05-15T11:12:25.702298\n",
            "  document_id: None\n",
            "  relative_path: Drop shipping.docx\n",
            "\n",
            "Entry 3:\n",
            "  id: 16\n",
            "  filename: Book.xlsx\n",
            "  file_path: app/data/uploads/Book.xlsx\n",
            "  created_at: 2025-05-15T11:12:25.702298\n",
            "  document_id: None\n",
            "  relative_path: Book.xlsx\n",
            "\n",
            "... and 95 more entries\n",
            "\n",
            "Step 2: Loading target file...\n",
            "✅ Successfully loaded ../example_upload_data/uploaded_files-new.json\n",
            "   Contains 117 entries\n",
            "\n",
            "Sample from Target File\n",
            "=======================\n",
            "\n",
            "Entry 1:\n",
            "  id: 1\n",
            "  filename: .DS_Store\n",
            "  file_path: app/data/uploads/.DS_Store\n",
            "  created_at: 2025-06-07T16:25:46.032691\n",
            "  document_id: None\n",
            "  relative_path: .DS_Store\n",
            "\n",
            "Entry 2:\n",
            "  id: 2\n",
            "  filename: Icon%0D\n",
            "  file_path: app/data/uploads/Icon%0D\n",
            "  created_at: 2025-06-07T16:25:46.032691\n",
            "  document_id: None\n",
            "  relative_path: Icon\n",
            "\n",
            "Entry 3:\n",
            "  id: 3\n",
            "  filename: Datenschutzerklärung Heier Grundschule.docx\n",
            "  file_path: app/data/uploads/Datenschutzerklärung Heier Grundschule.docx\n",
            "  created_at: 2025-06-07T16:25:46.032691\n",
            "  document_id: None\n",
            "  relative_path: Datenschutzerklärung Heier Grundschule.docx\n",
            "\n",
            "... and 114 more entries\n",
            "\n",
            "Step 3: Creating filename to ID mapping...\n",
            "Created mapping for 108 filenames\n",
            "\n",
            "Step 4: Merging files...\n",
            "Updated 'Datenschutzerklärung Heier Grundschule.docx': ID 12 → 3\n",
            "Updated 'Drop shipping.docx': ID 13 → 4\n",
            "Updated 'Book.xlsx': ID 16 → 7\n",
            "Updated 'Rechner 2k.docx': ID 19 → 10\n",
            "Updated 'Erklärung.pdf': ID 21 → 39\n",
            "Updated 'Empfehlungsschreiben Leon Bartz.pdf': ID 23 → 41\n",
            "Updated 'anlage-1-zb-rmv.pdf': ID 24 → 42\n",
            "Updated 'vn-2Bsb_ab_01.10.2020-1.docx': ID 25 → 43\n",
            "Updated '2101gr002a_Bartz_ZB_27.01.2021.pdf': ID 26 → 44\n",
            "Updated 'anlage-1.pdf': ID 27 → 45\n",
            "Updated '20210302-1000552834-umsatz.CSV': ID 29 → 47\n",
            "Updated '388802_Quittung.pdf': ID 30 → 48\n",
            "Updated 'Alles.xlsx': ID 31 → 53\n",
            "Updated 'Router und Telefon.pdf': ID 32 → 50\n",
            "Updated 'Druckerpatrone.pdf': ID 33 → 51\n",
            "Updated '88667.PDF': ID 34 → 52\n",
            "🔄 Skipping duplicate: 'Alles.xlsx' at 'app/data/uploads/Alles.xlsx'\n",
            "Updated '04-2021.pdf': ID 36 → 54\n",
            "Updated '12-2021.pdf': ID 37 → 55\n",
            "Updated '08-2021.pdf': ID 38 → 56\n",
            "Updated '02-2021.pdf': ID 39 → 57\n",
            "Updated '10-2021.pdf': ID 40 → 58\n",
            "Updated '06-2021.pdf': ID 41 → 59\n",
            "Updated 'Vorlage.pdf': ID 42 → 60\n",
            "Updated '01-2022.pdf': ID 43 → 61\n",
            "Updated 'Businessplan 02.12.21 DRAW.docx': ID 46 → 112\n",
            "Updated 'Businessplan 26.05.2021 (1).docx': ID 47 → 65\n",
            "Updated 'Beratungsvertrag.docx': ID 52 → 70\n",
            "Updated 'Hauptformular.docx': ID 53 → 75\n",
            "Updated 'AVV.doc': ID 54 → 76\n",
            "Updated 'AGB.docx': ID 55 → 78\n",
            "Updated 'Hauptformular[42].pdf': ID 56 → 74\n",
            "🔄 Skipping duplicate: 'Hauptformular.docx' at 'app/data/uploads/Hauptformular.docx'\n",
            "🔄 Skipping duplicate: 'AVV.doc' at 'app/data/uploads/AVV.doc'\n",
            "Updated 'Hauptformular[41].docx': ID 59 → 77\n",
            "🔄 Skipping duplicate: 'AGB.docx' at 'app/data/uploads/AGB.docx'\n",
            "Updated 'Hauptformular[41].pdf': ID 61 → 79\n",
            "Updated 'AGB_Vorlage.docx': ID 62 → 80\n",
            "Updated 'Hauptvertrag_Vorlage.docx': ID 63 → 81\n",
            "Updated 'AVV_Vorlage.doc': ID 64 → 87\n",
            "Updated 'Vertragsformular_V2.docx': ID 68 → 86\n",
            "🔄 Skipping duplicate: 'AVV_Vorlage.doc' at 'app/data/uploads/AVV_Vorlage.doc'\n",
            "Updated 'Leistungsbeschreibung V2.docx': ID 70 → 88\n",
            "Updated 'Ideenpapier Leon Bartz 3.docx': ID 71 → 89\n",
            "Updated 'FinalIdeenpapierGsnrw - Old.docx': ID 72 → 90\n",
            "Updated 'Ideenpapier Leon Bartz-1.docx': ID 73 → 91\n",
            "Updated 'ideenpapier_gsnrw.docx': ID 75 → 93\n",
            "Updated 'Ideenpapier Leon Bartz.docx': ID 76 → 94\n",
            "Updated 'Pitch.pptx': ID 77 → 95\n",
            "Updated 'GründerStipendiumIdeenpapier.docx': ID 78 → 96\n",
            "Updated 'Leitfragen Canvas.pptx': ID 79 → 97\n",
            "Updated 'Schul gespräche.xlsx': ID 80 → 98\n",
            "Updated 'Bericht 27.06.2022.docx': ID 81 → 99\n",
            "Updated 'Geschäftsmodell Vision.docx': ID 82 → 100\n",
            "Updated 'Fixkosten.xlsx': ID 83 → 101\n",
            "Updated 'Bericht 27.06.2022 copy.docx': ID 84 → 102\n",
            "Updated 'Änderungsliste.docx': ID 85 → 103\n",
            "Updated 'Mögliche Preiskalkulationen.docx': ID 86 → 104\n",
            "Updated 'Vergleich Develop 4 Future vs Schulmanager 14.02.2021.docx': ID 87 → 105\n",
            "Updated 'Todo Liste Schule.docx': ID 88 → 106\n",
            "Updated 'Meilenstein-Grobplanung.xlsx': ID 89 → 107\n",
            "Updated 'Preiskalkulation_Dienstleistung_und_Handwerk_-_Tool.xlsx': ID 90 → 108\n",
            "Updated 'Meilensteinplan-Vorlage-Excel.xlsx': ID 91 → 109\n",
            "Updated 'Bericht 29.06.2022.docx': ID 92 → 110\n",
            "Updated 'Businessplan 03.12.2021.docx': ID 93 → 111\n",
            "🔄 Skipping duplicate: 'Businessplan 02.12.21 DRAW.docx' at 'app/data/uploads/Businessplan 02.12.21 DRAW.docx'\n",
            "Updated 'Businessplan Finanzteil 03.12.2021.xlsx': ID 95 → 113\n",
            "Updated 'Businessplan 27.04.2021.docx': ID 96 → 114\n",
            "Updated 'Buisnessplan 14.02.2021.docx': ID 97 → 115\n",
            "Updated 'Businessplan 01.12.2021.docx': ID 98 → 116\n",
            "Updated 'Businessplan 26.05.2021.docx': ID 99 → 117\n",
            "Updated 'KI_Projekt_Stellenanzeige.txt': ID 101 → 12\n",
            "Updated 'KI_Projekt_Risikoanalyse.txt': ID 102 → 13\n",
            "Updated 'SmartKlassenzimmer_Kostenkalkulation.csv': ID 103 → 14\n",
            "Updated 'Einladung_Sommerfest_2025.pdf.txt': ID 104 → 15\n",
            "Updated 'KI_Projekt_Pressemitteilung.txt': ID 105 → 16\n",
            "Updated 'KI_Projekt_Feedbackbogen_Lehrkraefte.txt': ID 106 → 17\n",
            "Updated 'SmartKlassenzimmer_Elterninfo.txt': ID 107 → 18\n",
            "Updated 'SmartKlassenzimmer_Risikoanalyse.txt': ID 108 → 19\n",
            "Updated 'KI_Projekt_Memo.txt': ID 109 → 20\n",
            "Updated 'KI_Projekt_Besprechungsprotokoll_2025-06-05.txt': ID 110 → 21\n",
            "Updated 'KI_Projekt_Elterninfo.pdf.txt': ID 111 → 22\n",
            "Updated 'Rechnung_2025-05-20_Musterfirma.pdf.txt': ID 112 → 23\n",
            "Updated 'SmartKlassenzimmer_Projektbeschreibung.txt': ID 113 → 24\n",
            "Updated 'SmartKlassenzimmer_Pressemitteilung.txt': ID 114 → 25\n",
            "Updated 'KI_Projekt_Kostenkalkulation.csv': ID 115 → 26\n",
            "Updated 'SmartKlassenzimmer_Stellenanzeige_IT-Administrator.txt': ID 116 → 27\n",
            "Updated 'SmartKlassenzimmer_TechnischesKonzept.txt': ID 117 → 28\n",
            "Updated 'KI_Projekt_TechnischesKonzept.txt': ID 118 → 29\n",
            "Updated 'Bilanz_2024.csv': ID 119 → 30\n",
            "Updated 'Bilanz_2025.csv': ID 120 → 31\n",
            "Updated 'KI_Projekt_Datenschutzkonzept.txt': ID 121 → 32\n",
            "Updated 'KI_Projekt_Elternabend_Fragen_Antworten.txt': ID 122 → 33\n",
            "Updated 'SmartKlassenzimmer_FAQ_Eltern.txt': ID 123 → 34\n",
            "Updated 'KI_Projekt_Meilensteinplan.csv': ID 124 → 35\n",
            "Updated 'SmartKlassenzimmer_Meilensteinplan.csv': ID 125 → 36\n",
            "Updated 'Teammeeting_Protokoll_2025-05-10.txt': ID 126 → 37\n",
            "Updated 'SmartKlassenzimmer_Feedbackbogen_Lehrkraefte.txt': ID 127 → 38\n",
            "\n",
            "📊 Merge Summary:\n",
            "   Total entries processed: 98\n",
            "   Duplicates removed: 6\n",
            "   Unique entries kept: 92\n",
            "   IDs updated: 92\n",
            "   IDs unchanged: 0\n",
            "\n",
            "Step 5: Saving merged file...\n",
            "✅ Successfully saved 92 entries to ../example_upload_data/uploaded_files-merged-100.json\n",
            "\n",
            "Sample from Merged File\n",
            "=======================\n",
            "\n",
            "Entry 1:\n",
            "  id: 3\n",
            "  filename: Datenschutzerklärung Heier Grundschule.docx\n",
            "  file_path: app/data/uploads/Datenschutzerklärung Heier Grundschule.docx\n",
            "  created_at: 2025-05-15T11:12:25.702298\n",
            "  document_id: None\n",
            "  relative_path: Datenschutzerklärung Heier Grundschule.docx\n",
            "\n",
            "Entry 2:\n",
            "  id: 4\n",
            "  filename: Drop shipping.docx\n",
            "  file_path: app/data/uploads/Drop shipping.docx\n",
            "  created_at: 2025-05-15T11:12:25.702298\n",
            "  document_id: None\n",
            "  relative_path: Drop shipping.docx\n",
            "\n",
            "Entry 3:\n",
            "  id: 7\n",
            "  filename: Book.xlsx\n",
            "  file_path: app/data/uploads/Book.xlsx\n",
            "  created_at: 2025-05-15T11:12:25.702298\n",
            "  document_id: None\n",
            "  relative_path: Book.xlsx\n",
            "\n",
            "... and 89 more entries\n",
            "\n",
            "🎉 Process completed successfully!\n",
            "   Merged file saved as: ../example_upload_data/uploaded_files-merged-100.json\n"
          ]
        }
      ],
      "source": [
        "# Main execution\n",
        "print(\"🚀 Starting JSON file merge process...\\n\")\n",
        "\n",
        "# Step 1: Load source file (contains all file metadata)\n",
        "print(\"Step 1: Loading source file...\")\n",
        "source_data = load_json_file(SOURCE_FILE)\n",
        "\n",
        "if not source_data:\n",
        "    print(\"❌ Cannot proceed without source data\")\n",
        "else:\n",
        "    display_sample_data(source_data, \"Sample from Source File\")\n",
        "    \n",
        "    # Step 2: Load target file (contains new IDs)\n",
        "    print(f\"\\nStep 2: Loading target file...\")\n",
        "    target_data = load_json_file(TARGET_FILE)\n",
        "    \n",
        "    if not target_data:\n",
        "        print(\"❌ Cannot proceed without target data\")\n",
        "    else:\n",
        "        display_sample_data(target_data, \"Sample from Target File\")\n",
        "        \n",
        "        # Step 3: Create filename to ID mapping from target file\n",
        "        print(f\"\\nStep 3: Creating filename to ID mapping...\")\n",
        "        id_mapping = create_filename_to_id_mapping(target_data)\n",
        "        \n",
        "        if not id_mapping:\n",
        "            print(\"❌ No ID mapping created\")\n",
        "        else:\n",
        "            # Step 4: Merge the files\n",
        "            print(f\"\\nStep 4: Merging files...\")\n",
        "            merged_data = merge_json_files(source_data, id_mapping)\n",
        "            \n",
        "            # Step 5: Save the result\n",
        "            print(f\"\\nStep 5: Saving merged file...\")\n",
        "            if save_json_file(merged_data, OUTPUT_FILE):\n",
        "                display_sample_data(merged_data, \"Sample from Merged File\")\n",
        "                print(f\"\\n🎉 Process completed successfully!\")\n",
        "                print(f\"   Merged file saved as: {OUTPUT_FILE}\")\n",
        "            else:\n",
        "                print(\"❌ Failed to save merged file\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Configuration Options\n",
        "\n",
        "You can modify the file paths above to work with different JSON files:\n",
        "\n",
        "- `SOURCE_FILE`: The file containing all the metadata you want to keep\n",
        "- `TARGET_FILE`: The file containing the new IDs you want to use\n",
        "- `OUTPUT_FILE`: Where to save the merged result\n",
        "\n",
        "## How it works\n",
        "\n",
        "1. **Loading**: Both JSON files are loaded and validated\n",
        "2. **Mapping**: A filename-to-ID mapping is created from the target file\n",
        "3. **Merging**: Each entry from the source file is updated with the corresponding ID from the target file\n",
        "4. **Matching**: Files are matched by their `filename` field\n",
        "5. **Output**: A new JSON file is created with all source metadata but updated IDs\n",
        "\n",
        "## Sample Usage\n",
        "\n",
        "If you have different file names, just update the variables in the first code cell and run all cells again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 File Analysis\n",
            "==================================================\n",
            "Source file entries: 98\n",
            "Target file entries: 117\n",
            "Unique filenames in source: 92\n",
            "Unique filenames in target: 108\n",
            "\n",
            "⚠️  Files in target but not in source (16):\n",
            "   - .849C9593-D756-4E56-8D6E-42412F2A707B\n",
            "   - .DS_Store\n",
            "   - Becke Beratungsvertrag.pages\n",
            "   - Becke DSVGO.pages\n",
            "   - Becke Servicevertrag.pages\n",
            "   - Book 1.xlsx\n",
            "   - IMG_0053.jpeg\n",
            "   - Icon%0D\n",
            "   - Liste mit Produkten und Ranking.xlsx\n",
            "   - Untitled Diagram.drawio\n",
            "   - ideenpapier_gsnrw.pages\n",
            "   - logo.png\n",
            "   - v1_1_II.jpg\n",
            "   - v1_2_II.jpg\n",
            "   - v2_1_II.jpg\n",
            "   - v2_2_II.jpg\n",
            "\n",
            "✅ Files found in both (92):\n",
            "   - Datenschutzerklärung Heier Grundschule.docx\n",
            "   - KI_Projekt_Elterninfo.pdf.txt\n",
            "   - KI_Projekt_Feedbackbogen_Lehrkraefte.txt\n",
            "   - KI_Projekt_Kostenkalkulation.csv\n",
            "   - Meilensteinplan-Vorlage-Excel.xlsx\n",
            "   ... and 87 more\n"
          ]
        }
      ],
      "source": [
        "# Optional: Additional analysis and utilities\n",
        "\n",
        "def analyze_files_difference(source_data: List[Dict[str, Any]], \n",
        "                           target_data: List[Dict[str, Any]]):\n",
        "    \"\"\"Analyze differences between source and target files.\"\"\"\n",
        "    print(\"🔍 File Analysis\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    source_filenames = {entry.get('filename') for entry in source_data}\n",
        "    target_filenames = {entry.get('filename') for entry in target_data}\n",
        "    \n",
        "    print(f\"Source file entries: {len(source_data)}\")\n",
        "    print(f\"Target file entries: {len(target_data)}\")\n",
        "    print(f\"Unique filenames in source: {len(source_filenames)}\")\n",
        "    print(f\"Unique filenames in target: {len(target_filenames)}\")\n",
        "    \n",
        "    # Files in source but not in target\n",
        "    only_in_source = source_filenames - target_filenames\n",
        "    if only_in_source:\n",
        "        print(f\"\\n⚠️  Files in source but not in target ({len(only_in_source)}):\")\n",
        "        for filename in sorted([f for f in only_in_source if f is not None]):\n",
        "            print(f\"   - {filename}\")\n",
        "    \n",
        "    # Files in target but not in source\n",
        "    only_in_target = target_filenames - source_filenames\n",
        "    if only_in_target:\n",
        "        print(f\"\\n⚠️  Files in target but not in source ({len(only_in_target)}):\")\n",
        "        for filename in sorted([f for f in only_in_target if f is not None]):\n",
        "            print(f\"   - {filename}\")\n",
        "    \n",
        "    # Common files\n",
        "    common_files = source_filenames & target_filenames\n",
        "    print(f\"\\n✅ Files found in both ({len(common_files)}):\")\n",
        "    for filename in sorted([f for f in list(common_files)[:5] if f is not None]):  # Show first 5\n",
        "        print(f\"   - {filename}\")\n",
        "    if len(common_files) > 5:\n",
        "        print(f\"   ... and {len(common_files) - 5} more\")\n",
        "\n",
        "# Uncomment the following lines to run the analysis\n",
        "# if 'source_data' in locals() and 'target_data' in locals():\n",
        "#     analyze_files_difference(source_data, target_data)\n",
        "analyze_files_difference(source_data, target_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117]\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "requested_files = [3, 4, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 70, 74, 75, 76, 77, 78, 79, 80, 81, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117]\n",
        "\n",
        "existing_files = []\n",
        "\n",
        "# request http://localhost:9877/files/ and get all the ids\n",
        "response = requests.get(\"http://localhost:9877/files/\")\n",
        "ids = [file[\"id\"] for file in response.json()]\n",
        "\n",
        "print(ids)\n",
        "\n",
        "# compare the ids with the requested_files\n",
        "for id in requested_files:\n",
        "    if id not in ids:\n",
        "        print(f\"File with id {id} not found\")\n",
        "\n",
        "# save the ids to a json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Successfully loaded ../example_upload_data/uploaded_files-merged-100.json\n",
            "   Contains 98 entries\n",
            "\n",
            "Found duplicate entries:\n",
            "\n",
            "ID 53 appears 2 times:\n",
            "  - Alles.xlsx (app/data/uploads/Alles.xlsx)\n",
            "  - Alles.xlsx (app/data/uploads/Alles.xlsx)\n",
            "\n",
            "ID 112 appears 2 times:\n",
            "  - Businessplan 02.12.21 DRAW.docx (app/data/uploads/Businessplan 02.12.21 DRAW.docx)\n",
            "  - Businessplan 02.12.21 DRAW.docx (app/data/uploads/Businessplan 02.12.21 DRAW.docx)\n",
            "\n",
            "ID 75 appears 2 times:\n",
            "  - Hauptformular.docx (app/data/uploads/Hauptformular.docx)\n",
            "  - Hauptformular.docx (app/data/uploads/Hauptformular.docx)\n",
            "\n",
            "ID 76 appears 2 times:\n",
            "  - AVV.doc (app/data/uploads/AVV.doc)\n",
            "  - AVV.doc (app/data/uploads/AVV.doc)\n",
            "\n",
            "ID 78 appears 2 times:\n",
            "  - AGB.docx (app/data/uploads/AGB.docx)\n",
            "  - AGB.docx (app/data/uploads/AGB.docx)\n",
            "\n",
            "ID 87 appears 2 times:\n",
            "  - AVV_Vorlage.doc (app/data/uploads/AVV_Vorlage.doc)\n",
            "  - AVV_Vorlage.doc (app/data/uploads/AVV_Vorlage.doc)\n"
          ]
        }
      ],
      "source": [
        "output_file_json = load_json_file(OUTPUT_FILE)\n",
        "\n",
        "# Find duplicate entries by id\n",
        "id_counts = {}\n",
        "for entry in output_file_json:\n",
        "    file_id = entry['id']\n",
        "    if file_id in id_counts:\n",
        "        id_counts[file_id].append(entry)\n",
        "    else:\n",
        "        id_counts[file_id] = [entry]\n",
        "\n",
        "# Print duplicates\n",
        "duplicates = {id: entries for id, entries in id_counts.items() if len(entries) > 1}\n",
        "if duplicates:\n",
        "    print(\"\\nFound duplicate entries:\")\n",
        "    for file_id, entries in duplicates.items():\n",
        "        print(f\"\\nID {file_id} appears {len(entries)} times:\")\n",
        "        for entry in entries:\n",
        "            print(f\"  - {entry['filename']} ({entry['file_path']})\")\n",
        "else:\n",
        "    print(\"\\nNo duplicate IDs found\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Regenerating merged file with duplicate removal...\n",
            "\n",
            "Step 1: Creating filename to ID mapping...\n",
            "Created mapping for 108 filenames\n",
            "\n",
            "Step 2: Merging files with duplicate removal...\n",
            "Updated 'Datenschutzerklärung Heier Grundschule.docx': ID 12 → 3\n",
            "Updated 'Drop shipping.docx': ID 13 → 4\n",
            "Updated 'Book.xlsx': ID 16 → 7\n",
            "Updated 'Rechner 2k.docx': ID 19 → 10\n",
            "Updated 'Erklärung.pdf': ID 21 → 39\n",
            "Updated 'Empfehlungsschreiben Leon Bartz.pdf': ID 23 → 41\n",
            "Updated 'anlage-1-zb-rmv.pdf': ID 24 → 42\n",
            "Updated 'vn-2Bsb_ab_01.10.2020-1.docx': ID 25 → 43\n",
            "Updated '2101gr002a_Bartz_ZB_27.01.2021.pdf': ID 26 → 44\n",
            "Updated 'anlage-1.pdf': ID 27 → 45\n",
            "Updated '20210302-1000552834-umsatz.CSV': ID 29 → 47\n",
            "Updated '388802_Quittung.pdf': ID 30 → 48\n",
            "Updated 'Alles.xlsx': ID 31 → 53\n",
            "Updated 'Router und Telefon.pdf': ID 32 → 50\n",
            "Updated 'Druckerpatrone.pdf': ID 33 → 51\n",
            "Updated '88667.PDF': ID 34 → 52\n",
            "Updated 'Alles.xlsx': ID 35 → 53\n",
            "Updated '04-2021.pdf': ID 36 → 54\n",
            "Updated '12-2021.pdf': ID 37 → 55\n",
            "Updated '08-2021.pdf': ID 38 → 56\n",
            "Updated '02-2021.pdf': ID 39 → 57\n",
            "Updated '10-2021.pdf': ID 40 → 58\n",
            "Updated '06-2021.pdf': ID 41 → 59\n",
            "Updated 'Vorlage.pdf': ID 42 → 60\n",
            "Updated '01-2022.pdf': ID 43 → 61\n",
            "Updated 'Businessplan 02.12.21 DRAW.docx': ID 46 → 112\n",
            "Updated 'Businessplan 26.05.2021 (1).docx': ID 47 → 65\n",
            "Updated 'Beratungsvertrag.docx': ID 52 → 70\n",
            "Updated 'Hauptformular.docx': ID 53 → 75\n",
            "Updated 'AVV.doc': ID 54 → 76\n",
            "Updated 'AGB.docx': ID 55 → 78\n",
            "Updated 'Hauptformular[42].pdf': ID 56 → 74\n",
            "Updated 'Hauptformular.docx': ID 57 → 75\n",
            "Updated 'AVV.doc': ID 58 → 76\n",
            "Updated 'Hauptformular[41].docx': ID 59 → 77\n",
            "Updated 'AGB.docx': ID 60 → 78\n",
            "Updated 'Hauptformular[41].pdf': ID 61 → 79\n",
            "Updated 'AGB_Vorlage.docx': ID 62 → 80\n",
            "Updated 'Hauptvertrag_Vorlage.docx': ID 63 → 81\n",
            "Updated 'AVV_Vorlage.doc': ID 64 → 87\n",
            "Updated 'Vertragsformular_V2.docx': ID 68 → 86\n",
            "Updated 'AVV_Vorlage.doc': ID 69 → 87\n",
            "Updated 'Leistungsbeschreibung V2.docx': ID 70 → 88\n",
            "Updated 'Ideenpapier Leon Bartz 3.docx': ID 71 → 89\n",
            "Updated 'FinalIdeenpapierGsnrw - Old.docx': ID 72 → 90\n",
            "Updated 'Ideenpapier Leon Bartz-1.docx': ID 73 → 91\n",
            "Updated 'ideenpapier_gsnrw.docx': ID 75 → 93\n",
            "Updated 'Ideenpapier Leon Bartz.docx': ID 76 → 94\n",
            "Updated 'Pitch.pptx': ID 77 → 95\n",
            "Updated 'GründerStipendiumIdeenpapier.docx': ID 78 → 96\n",
            "Updated 'Leitfragen Canvas.pptx': ID 79 → 97\n",
            "Updated 'Schul gespräche.xlsx': ID 80 → 98\n",
            "Updated 'Bericht 27.06.2022.docx': ID 81 → 99\n",
            "Updated 'Geschäftsmodell Vision.docx': ID 82 → 100\n",
            "Updated 'Fixkosten.xlsx': ID 83 → 101\n",
            "Updated 'Bericht 27.06.2022 copy.docx': ID 84 → 102\n",
            "Updated 'Änderungsliste.docx': ID 85 → 103\n",
            "Updated 'Mögliche Preiskalkulationen.docx': ID 86 → 104\n",
            "Updated 'Vergleich Develop 4 Future vs Schulmanager 14.02.2021.docx': ID 87 → 105\n",
            "Updated 'Todo Liste Schule.docx': ID 88 → 106\n",
            "Updated 'Meilenstein-Grobplanung.xlsx': ID 89 → 107\n",
            "Updated 'Preiskalkulation_Dienstleistung_und_Handwerk_-_Tool.xlsx': ID 90 → 108\n",
            "Updated 'Meilensteinplan-Vorlage-Excel.xlsx': ID 91 → 109\n",
            "Updated 'Bericht 29.06.2022.docx': ID 92 → 110\n",
            "Updated 'Businessplan 03.12.2021.docx': ID 93 → 111\n",
            "Updated 'Businessplan 02.12.21 DRAW.docx': ID 94 → 112\n",
            "Updated 'Businessplan Finanzteil 03.12.2021.xlsx': ID 95 → 113\n",
            "Updated 'Businessplan 27.04.2021.docx': ID 96 → 114\n",
            "Updated 'Buisnessplan 14.02.2021.docx': ID 97 → 115\n",
            "Updated 'Businessplan 01.12.2021.docx': ID 98 → 116\n",
            "Updated 'Businessplan 26.05.2021.docx': ID 99 → 117\n",
            "Updated 'KI_Projekt_Stellenanzeige.txt': ID 101 → 12\n",
            "Updated 'KI_Projekt_Risikoanalyse.txt': ID 102 → 13\n",
            "Updated 'SmartKlassenzimmer_Kostenkalkulation.csv': ID 103 → 14\n",
            "Updated 'Einladung_Sommerfest_2025.pdf.txt': ID 104 → 15\n",
            "Updated 'KI_Projekt_Pressemitteilung.txt': ID 105 → 16\n",
            "Updated 'KI_Projekt_Feedbackbogen_Lehrkraefte.txt': ID 106 → 17\n",
            "Updated 'SmartKlassenzimmer_Elterninfo.txt': ID 107 → 18\n",
            "Updated 'SmartKlassenzimmer_Risikoanalyse.txt': ID 108 → 19\n",
            "Updated 'KI_Projekt_Memo.txt': ID 109 → 20\n",
            "Updated 'KI_Projekt_Besprechungsprotokoll_2025-06-05.txt': ID 110 → 21\n",
            "Updated 'KI_Projekt_Elterninfo.pdf.txt': ID 111 → 22\n",
            "Updated 'Rechnung_2025-05-20_Musterfirma.pdf.txt': ID 112 → 23\n",
            "Updated 'SmartKlassenzimmer_Projektbeschreibung.txt': ID 113 → 24\n",
            "Updated 'SmartKlassenzimmer_Pressemitteilung.txt': ID 114 → 25\n",
            "Updated 'KI_Projekt_Kostenkalkulation.csv': ID 115 → 26\n",
            "Updated 'SmartKlassenzimmer_Stellenanzeige_IT-Administrator.txt': ID 116 → 27\n",
            "Updated 'SmartKlassenzimmer_TechnischesKonzept.txt': ID 117 → 28\n",
            "Updated 'KI_Projekt_TechnischesKonzept.txt': ID 118 → 29\n",
            "Updated 'Bilanz_2024.csv': ID 119 → 30\n",
            "Updated 'Bilanz_2025.csv': ID 120 → 31\n",
            "Updated 'KI_Projekt_Datenschutzkonzept.txt': ID 121 → 32\n",
            "Updated 'KI_Projekt_Elternabend_Fragen_Antworten.txt': ID 122 → 33\n",
            "Updated 'SmartKlassenzimmer_FAQ_Eltern.txt': ID 123 → 34\n",
            "Updated 'KI_Projekt_Meilensteinplan.csv': ID 124 → 35\n",
            "Updated 'SmartKlassenzimmer_Meilensteinplan.csv': ID 125 → 36\n",
            "Updated 'Teammeeting_Protokoll_2025-05-10.txt': ID 126 → 37\n",
            "Updated 'SmartKlassenzimmer_Feedbackbogen_Lehrkraefte.txt': ID 127 → 38\n",
            "\n",
            "📊 Merge Summary:\n",
            "   Total entries processed: 98\n",
            "   IDs updated: 98\n",
            "   IDs unchanged: 0\n",
            "\n",
            "Step 3: Saving clean merged file...\n",
            "✅ Successfully saved 98 entries to ../example_upload_data/uploaded_files-merged-100.json\n",
            "\n",
            "Sample from Clean Merged File\n",
            "=============================\n",
            "\n",
            "Entry 1:\n",
            "  id: 3\n",
            "  filename: Datenschutzerklärung Heier Grundschule.docx\n",
            "  file_path: app/data/uploads/Datenschutzerklärung Heier Grundschule.docx\n",
            "  created_at: 2025-05-15T11:12:25.702298\n",
            "  document_id: None\n",
            "  relative_path: Datenschutzerklärung Heier Grundschule.docx\n",
            "\n",
            "Entry 2:\n",
            "  id: 4\n",
            "  filename: Drop shipping.docx\n",
            "  file_path: app/data/uploads/Drop shipping.docx\n",
            "  created_at: 2025-05-15T11:12:25.702298\n",
            "  document_id: None\n",
            "  relative_path: Drop shipping.docx\n",
            "\n",
            "Entry 3:\n",
            "  id: 7\n",
            "  filename: Book.xlsx\n",
            "  file_path: app/data/uploads/Book.xlsx\n",
            "  created_at: 2025-05-15T11:12:25.702298\n",
            "  document_id: None\n",
            "  relative_path: Book.xlsx\n",
            "\n",
            "... and 95 more entries\n",
            "\n",
            "🔍 Verifying no duplicates remain...\n",
            "❌ Still found duplicate entries:\n",
            "   ID 53 appears 2 times\n",
            "   ID 112 appears 2 times\n",
            "   ID 75 appears 2 times\n",
            "   ID 76 appears 2 times\n",
            "   ID 78 appears 2 times\n",
            "   ID 87 appears 2 times\n",
            "\n",
            "🎉 Clean merged file saved as: ../example_upload_data/uploaded_files-merged-100.json\n",
            "   Total unique entries: 98\n"
          ]
        }
      ],
      "source": [
        "# Regenerate the merged file with duplicate handling\n",
        "print(\"🔄 Regenerating merged file with duplicate removal...\\n\")\n",
        "\n",
        "if 'source_data' in locals() and 'target_data' in locals():\n",
        "    # Step 1: Create filename to ID mapping from target file\n",
        "    print(\"Step 1: Creating filename to ID mapping...\")\n",
        "    id_mapping = create_filename_to_id_mapping(target_data)\n",
        "    \n",
        "    # Step 2: Merge files with duplicate removal\n",
        "    print(f\"\\nStep 2: Merging files with duplicate removal...\")\n",
        "    merged_data_clean = merge_json_files(source_data, id_mapping)\n",
        "    \n",
        "    # Step 3: Save the clean result\n",
        "    print(f\"\\nStep 3: Saving clean merged file...\")\n",
        "    if save_json_file(merged_data_clean, OUTPUT_FILE):\n",
        "        display_sample_data(merged_data_clean, \"Sample from Clean Merged File\")\n",
        "        \n",
        "        # Verify no duplicates remain\n",
        "        print(f\"\\n🔍 Verifying no duplicates remain...\")\n",
        "        id_counts_clean = {}\n",
        "        for entry in merged_data_clean:\n",
        "            file_id = entry['id']\n",
        "            if file_id in id_counts_clean:\n",
        "                id_counts_clean[file_id].append(entry)\n",
        "            else:\n",
        "                id_counts_clean[file_id] = [entry]\n",
        "        \n",
        "        duplicates_clean = {id: entries for id, entries in id_counts_clean.items() if len(entries) > 1}\n",
        "        if duplicates_clean:\n",
        "            print(\"❌ Still found duplicate entries:\")\n",
        "            for file_id, entries in duplicates_clean.items():\n",
        "                print(f\"   ID {file_id} appears {len(entries)} times\")\n",
        "        else:\n",
        "            print(\"✅ No duplicate IDs found - file is clean!\")\n",
        "        \n",
        "        print(f\"\\n🎉 Clean merged file saved as: {OUTPUT_FILE}\")\n",
        "        print(f\"   Total unique entries: {len(merged_data_clean)}\")\n",
        "    else:\n",
        "        print(\"❌ Failed to save clean merged file\")\n",
        "else:\n",
        "    print(\"❌ Source and target data not available. Please run the cells above first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rag-eval-bachelor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
