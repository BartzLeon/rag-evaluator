\section{Konkretisierung der versuche}

\subsection{Dokumentenverarbeitung}

Damit die Dokumente in der Vektordatenbank gesichert werden können müssen sie erst zu Vektoren konvertiert werden. Das wird mit Embeddings gemacht, hier werden wir auch wieder die von OpenAI verwenden aber auch eine Open-Source Variante von nomic.ai.

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Embedding-Modell} & \textbf{10} & \textbf{100} & \textbf{400} \\
        \hline
        openai/text-embedding-3-large & X & X & X \\
        ollama/nomic-embed-text       & X & X & X \\
        \hline
    \end{tabular}
    \caption{Kombinationen aus Dokumentanzahl und Embedding-Modell für die Versuche (X = Kombination wird getestet)}
    \label{tab:dokument-erstellung}
\end{table}

\subsection{Testset-Generierung}

Um die optimale Anzahl an Fragen pro Testset zu untersuchen, werden folgende Kombinationen generiert:

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Dokumentanzahl} & \textbf{Anzahl Fragen pro Testset} & \textbf{Anzahl Testsets pro Modell} \\
        \hline
        10   & 15, 30    & 2 \\
        100  & 50, 100   & 2 \\
        400 & 150, 300  & 2 \\
        \hline
        \multicolumn{2}{|c|}{\textbf{Summe Testsets pro Modell}} & 6 \\
        \hline
    \end{tabular}
    \caption{Kombinationen aus Dokumentanzahl und Testset-Größe}
\end{table}

\subsection{Bewertung}
Um die Robustheit und Übertragbarkeit der Bewertungsergebnisse zu erhöhen, werden alle Kombinationen aus Embedding-Modell und Bewertungsmodell getestet. Das bedeutet, dass für jedes Testset sowohl openai/text-embedding-3-large als auch ollama/nomic-embed-text als Embedding-Modell verwendet werden und die Bewertung jeweils mit GPT-4 sowie Deepseek-R1 (ollama/deepseek-r1:7b) erfolgt. Insgesamt ergeben sich so 24 Versuche (2 Embeddings × 2 Bewerter × 6 Testset-Varianten).

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        \textbf{versuch} & \textbf{Embedding} & \textbf{Dokumente} & \textbf{Fragen} & \textbf{Bewerter} & \textbf{Richter} & \textbf{Wdh.} \\
        \hline
        1  & OAI-E & 10   & 15  & GPT-4 & GPT-4 & 1/1 \\
        2  & OAI-E & 10   & 30  & GPT-4 & GPT-4 & 4/4 \\
        3  & OAI-E & 100  & 50  & GPT-4 & GPT-4 & 1/1 \\
        4  & OAI-E & 100  & 100 & GPT-4 & GPT-4 & 4/4 \\
        5  & OAI-E & 400 & 150 & GPT-4 & GPT-4 & 1/1 \\
        6  & OAI-E & 400 & 300 & GPT-4 & GPT-4 & 1 \\
        \hline
        7  & OAI-E & 10   & 15  & DSK-R & DSK-R & 1 \\
        8  & OAI-E & 10   & 30  & DSK-R & DSK-R & 1 \\
        9  & OAI-E & 100  & 50  & DSK-R & DSK-R & 1 \\
        10 & OAI-E & 100  & 100 & DSK-R & DSK-R & 1 \\
        11 & OAI-E & 400 & 150 & DSK-R & DSK-R & 1 \\
        12 & OAI-E & 400 & 300 & DSK-R & DSK-R & 1 \\
        \hline
    \end{tabular}
    \caption{Übersicht aller 24 zu generierenden Bewertungsberichte mit Abkürzungen und Wiederholungen}
    \label{tab:bewertungsberichte}
\end{table}

\noindent
\textbf{Verwendete Abkürzungen in der Tabelle:}
\begin{itemize}
    \item \textbf{OAI-E} = openai/text-embedding-3-large
    \item \textbf{OLL-E} = ollama/nomic-embed-text
    \item \textbf{GPT-4} = openai/gpt-4
    \item \textbf{DSK-R} = ollama/deepseek-r1:7b
\end{itemize} 