\section{Konkretisierung der Versuche}

\subsection{Dokumentenverarbeitung}

Damit die Dokumente in der Vektordatenbank gesichert werden können, müssen sie erst in Vektoren konvertiert werden.
Hierfür wurden Embeddings von OpenAI sowie Open-Source-Embeddings von nomic.ai \cite{nomic_embed_text_v1_blog} verwendet.
Tabelle~\ref{tab:dokument-erstellung} zeigt die entsprechenden Kombinationen.

\begin{table}[htbp]
    \centering
    \caption[Kombinationen aus Dokumentenanzahl und Embedding-Modell]{Kombinationen aus Dokumentenanzahl und Embedding-Modell für die Versuche (X = Kombination wird getestet)}
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{Embedding-Modell} & \textbf{10} & \textbf{100} & \textbf{400} \\
        \hline
        openai/text-embedding-3-large & X & X & X \\
        ollama/nomic-embed-text       & X & X & X \\
        \hline
    \end{tabular}
    \label{tab:dokument-erstellung}
\end{table}

\subsection{Testset-Generierung}

Um die optimale Anzahl an Fragen pro Testset zu untersuchen, werden die in Tabelle~\ref{tab:testset_generation} dargestellten Kombinationen generiert:

\begin{table}[htbp]
    \centering
    \caption{Kombinationen aus Dokumentenanzahl und Testset-Größe}
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Dokumentenanzahl} & \textbf{Anzahl Fragen pro Testset} & \textbf{Anzahl Testsets pro Modell} \\
        \hline
        10   & 15, 30    & 2 \\
        100  & 50, 100   & 2 \\
        400 & 150, 300  & 2 \\
        \hline
        \multicolumn{2}{|c|}{\textbf{Summe Testsets pro Modell}} & 6 \\
        \hline
    \end{tabular}
    \label{tab:testset_generation}
\end{table}

\subsection{Bewertung}
\label{sec:bewertung}
Um die Robustheit und Übertragbarkeit der Bewertungsergebnisse zu erhöhen, werden alle Kombinationen aus Embedding-Modell und Bewertungsmodell getestet. Das bedeutet, dass für jedes Testset sowohl \textbf{openai/text-embedding-3-large} als auch \textbf{ollama/nomic-embed-text} als Embedding-Modell verwendet werden und die Bewertung jeweils mit \textbf{GPT-4} sowie \textbf{Deepseek-R1} (\textbf{ollama/deepseek-r1:7b}) erfolgt. Insgesamt ergeben sich so 24 Versuche (2 Embeddings $\times$ 2 Bewerter $\times$ 6 Testset-Varianten).
Diese werden in Tabelle~\ref{tab:bewertungsberichte} dargestellt.
\begin{table}[htbp]
    \centering
    \caption[Übersicht der Versuche]{Übersicht aller 12 zu generierenden Bewertungsberichte mit Abkürzungen und Wiederholungen}
    \begin{tabular}{|r|l|r|r|l|l|r|}
        \hline
        \textbf{Versuch} & \textbf{Embedding} & \textbf{Dokumente} & \textbf{Fragen} & \textbf{Bewerter} & \textbf{Richter} & \textbf{Wdh.} \\
        \hline
        1  & OAI-E & 10   & 15  & GPT-4 & GPT-4 & 1 \\
        2  & OAI-E & 10   & 30  & GPT-4 & GPT-4 & 4 \\
        3  & OAI-E & 100  & 50  & GPT-4 & GPT-4 & 1 \\
        4  & OAI-E & 100  & 100 & GPT-4 & GPT-4 & 4 \\
        5  & OAI-E & 400 & 150 & GPT-4 & GPT-4 & 1 \\
        6  & OAI-E & 400 & 300 & GPT-4 & GPT-4 & 1 \\
        \hline
        7  & OLL-E & 10   & 15  & DSK-R & DSK-R & 1 \\
        8  & OLL-E & 10   & 30  & DSK-R & DSK-R & 1 \\
        9  & OLL-E & 100  & 50  & DSK-R & DSK-R & 1 \\
        10 & OLL-E & 100  & 100 & DSK-R & DSK-R & 1 \\
        11 & OLL-E & 400 & 150 & DSK-R & DSK-R & 1 \\
        12 & OLL-E & 400 & 300 & DSK-R & DSK-R & 1 \\
        \hline
    \end{tabular}
    \label{tab:bewertungsberichte}
\end{table}

\noindent
\textbf{Verwendete Abkürzungen in der Tabelle:}
\begin{itemize}
    \item \textbf{OAI-E} = \textbf{openai/text-embedding-3-large}
    \item \textbf{OLL-E} = \textbf{ollama/nomic-embed-text}
    \item \textbf{GPT-4} = \textbf{openai/gpt-4}
    \item \textbf{DSK-R} = \textbf{ollama/deepseek-r1:7b}
\end{itemize}